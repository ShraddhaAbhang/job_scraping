'''
# Notes:

- Libraries Required:

        Install requests and BeautifulSoup via pip if you haven’t already:
                ~ pip install requests beautifulsoup4

- Respect Robots.txt and Terms of Service:

        Always check the robots.txt file of the website and adhere to their scraping policies.

- Handle Pagination:
        If the website has multiple pages of job listings, you may need to handle pagination by iterating through URLs or by interacting with the site’s navigation.

- Dynamic Content:
        For websites with dynamic content loaded via JavaScript, you might need a more advanced tool like Selenium or Playwright to interact with the page.

'''